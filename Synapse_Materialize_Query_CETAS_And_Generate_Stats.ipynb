{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Materialize query results on Synapse Serverless SQL using CETAS\n",
        "\n",
        "This notebook shows how to materialize query results in Synapse Serverless SQL using a straightforward pattern based on CREATE EXTERNAL TABLE AS SELECT (CETAS).\n",
        "\n",
        "Each time the notebook is executed:\n",
        "- The previous materialized external table (if it exists) is dropped.\n",
        "- The corresponding data files in Azure Data Lake Storage are deleted.\n",
        "- A new external table is created using CETAS based on a specified query.\n",
        "- After successful creation, column-level statistics are automatically generated using `CREATE STATISTICS` for all columns in the new table.\n",
        "\n",
        "This approach can be useful for materializing complex queries into reusable external tables.\n",
        "\n",
        "> ‚ö†Ô∏è **Disclaimer:** Although this notebook was developed by a Microsoft employee, it is not an officially supported solution. Customers should review and test the code thoroughly before using it in production scenarios.\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîß Configuration instructions\n",
        "\n",
        "Before running this notebook, please review and update the configuration values and SQL query below:\n",
        "\n",
        "1. `external_table`\n",
        "- **What it is**: The name of the external table to be created.\n",
        "- **Example**: `\"Sales_Materialized\"`\n",
        "\n",
        "---\n",
        "\n",
        "2. `workspace_name`\n",
        "- **What it is**: The name of your Synapse workspace (without the `-ondemand.sql.azuresynapse.net` suffix).\n",
        "- **Example**: `\"myworkspace\"`\n",
        "\n",
        "---\n",
        "\n",
        "3. `database_name`\n",
        "- **What it is**: The name of the SQL database where the external table will be created.\n",
        "- **Example**: `\"reportingdb\"`\n",
        "\n",
        "---\n",
        "\n",
        "4. `materialized_table_output_path`\n",
        "- **What it is**: The ADLS Gen2 path (ABFSS URI) where CETAS will write the external table files.\n",
        "- ‚ö†Ô∏è **Warning**: This folder will be fully deleted each time the notebook runs.\n",
        "- **Example**: `\"abfss://tables@<storageaccount>.dfs.core.windows.net/folder/materialized_table/\"`\n",
        "\n",
        "---\n",
        "\n",
        "5. CETAS SQL (`cetas_sql`)\n",
        "- **What it is**: Customize the `SELECT` statement and source path in the `OPENROWSET` clause.\n",
        "- **Example**: \n",
        "```sql\n",
        "  WITH (\n",
        "  LOCATION = '/folder/',\n",
        "  DATA_SOURCE = [data_source_name],\n",
        "  FILE_FORMAT = [file_format_name]\n",
        "  )\n",
        "AS\n",
        "  SELECT * FROM OPENROWSET(\n",
        "      BULK 'https://<storageaccount>.dfs.core.windows.net/<container>/source/*.parquet',\n",
        "      FORMAT = 'PARQUET'\n",
        "  ) AS [result]\n",
        "```\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from notebookutils import mssparkutils\n",
        "# -------------------------\n",
        "# CONFIGURATION\n",
        "# -------------------------\n",
        "CONFIG = {\n",
        "    \"external_table\": \"\",           # e.g., 'Sales_Materialized'\n",
        "    \"workspace_name\": \"\",          # e.g., 'myworkspace'\n",
        "    \"database_name\": \"\",               # e.g., 'reportingdb'\n",
        "\n",
        "    # ADLS path where CETAS will write the output files.\n",
        "    # ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è IMPORTANT: All existing contents in this folder will be deleted before recreating the external table    \n",
        "    \"materialized_table_output_path\": \"abfss://tables@storageaccount.dfs.core.windows.net/folder/materialized_table/\"\n",
        "}\n",
        "\n",
        "cetas_sql = f\"\"\"\n",
        "CREATE EXTERNAL TABLE {CONFIG['external_table']}\n",
        "    WITH (\n",
        "    LOCATION = '/folder_name/',\n",
        "    DATA_SOURCE = [data_source_name],\n",
        "    FILE_FORMAT = [file_format_name]\n",
        "    )\n",
        "AS\n",
        "    SELECT\n",
        "       *\n",
        "    FROM ...\n",
        "\"\"\"\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Define Utility Functions\n",
        "These functions will handle JDBC connection, table operations, and file deletion in ADLS.\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_jdbc_connection(config):\n",
        "    \"\"\"Establish a JDBC connection to Synapse Serverless using AAD token.\"\"\"\n",
        "    token = mssparkutils.credentials.getToken(\"DW\")\n",
        "    jdbc_url = (\n",
        "        f\"jdbc:sqlserver://{config['workspace_name']}-ondemand.sql.azuresynapse.net:1433;\"\n",
        "        f\"database={config['database_name']};\"\n",
        "        \"encrypt=true;\"\n",
        "        \"trustServerCertificate=false;\"\n",
        "        \"hostNameInCertificate=*.sql.azuresynapse.net;\"\n",
        "        \"loginTimeout=30;\"\n",
        "    )\n",
        "    props = spark._sc._jvm.java.util.Properties()\n",
        "    props.setProperty(\"accessToken\", token)\n",
        "    props.setProperty(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\")\n",
        "    return spark._sc._jvm.java.sql.DriverManager.getConnection(jdbc_url, props)\n",
        "\n",
        "\n",
        "def table_exists(stmt, table_name):\n",
        "    \"\"\"Check whether the external table exists in Synapse metadata.\"\"\"\n",
        "    query = f\"\"\"\n",
        "        SELECT 1\n",
        "        FROM sys.external_tables\n",
        "        WHERE name = '{table_name.split('.')[-1]}'\n",
        "    \"\"\"\n",
        "    rs = stmt.executeQuery(query)\n",
        "    return rs.next()\n",
        "\n",
        "\n",
        "def drop_external_table(stmt, table_name):\n",
        "    \"\"\"Drop the specified external table.\"\"\"\n",
        "    stmt.execute(f\"DROP EXTERNAL TABLE {table_name}\")\n",
        "    print(f\"‚úÖ Dropped external table `{table_name}`.\")\n",
        "\n",
        "\n",
        "def delete_adls_path(path):\n",
        "    \"\"\"Delete the contents of the given ADLS path.\"\"\"\n",
        "    if mssparkutils.fs.rm(path, recurse=True):\n",
        "        print(f\"‚úÖ Deleted ADLS path: {path}\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Path not found or already deleted: {path}\")\n",
        "\n",
        "\n",
        "def create_external_table(stmt, config):\n",
        "    \"\"\"Create a new external table using CETAS with the specified configuration.\"\"\"\n",
        "    location_folder = config['materialized_table_output_path'].rstrip('/').split('/')[-1] \n",
        "    stmt.execute(cetas_sql)\n",
        "    print(f\"‚úÖ Created external table `{config['external_table']}`.\")\n",
        "\n",
        "def create_statistics_for_external_table(config):\n",
        "    \"\"\"Generate and execute CREATE STATISTICS statements for each column of the external table.\"\"\"\n",
        "    conn = None\n",
        "    stmt = None\n",
        "    try:\n",
        "        conn = get_jdbc_connection(config)\n",
        "        stmt = conn.createStatement()\n",
        "\n",
        "        # Step 1: Generate the CREATE STATISTICS statements\n",
        "        table_name = config[\"external_table\"].split('.')[-1]\n",
        "        stats_sql = f\"\"\"\n",
        "        SELECT\n",
        "           'CREATE STATISTICS [' + 'Stats_' + c.name + '] ON [' + schema_name(o.schema_id) + '].[' + object_name(o.object_id) + '] ([' + c.name + ']) WITH FULLSCAN;' AS cmd_create\n",
        "        FROM sys.objects AS o\n",
        "        INNER JOIN sys.columns AS c \n",
        "           ON o.object_id = c.object_id\n",
        "        LEFT JOIN sys.stats_columns AS sc \n",
        "           ON sc.object_id = c.object_id AND sc.column_id = c.column_id\n",
        "        LEFT JOIN sys.stats AS s\n",
        "           ON s.object_id = sc.object_id AND s.stats_id = sc.stats_id\n",
        "        WHERE o.name = '{table_name}'\n",
        "        \"\"\"\n",
        "\n",
        "        rs = stmt.executeQuery(stats_sql)\n",
        "        commands = []\n",
        "\n",
        "        while rs.next():\n",
        "            commands.append(rs.getString(1))\n",
        "\n",
        "        if not commands:\n",
        "            print(f\"‚ÑπÔ∏è No statistics to create for table `{table_name}`.\")\n",
        "            return\n",
        "\n",
        "        # Step 2: Execute each CREATE STATISTICS command\n",
        "        print(f\"üìä Creating statistics for {len(commands)} columns in `{table_name}`...\")\n",
        "        for cmd in commands:\n",
        "            try:\n",
        "                stmt.execute(cmd)\n",
        "                print(f\"‚úÖ Executed: {cmd}\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Failed: {cmd}\\n   Reason: {e}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error while generating statistics: {e}\")\n",
        "        raise\n",
        "    finally:\n",
        "        if stmt:\n",
        "            stmt.close()\n",
        "        if conn:\n",
        "            conn.close()\n",
        "        print(\"üîö Statistics creation step completed.\")\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Main Logic Function\n",
        "This function orchestrates all the steps: drop table, delete files, and recreate the table.\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def refresh_external_table(config):\n",
        "    \"\"\"Main orchestration function to refresh the external table using CETAS and optionally create column statistics.\"\"\"\n",
        "    conn = None\n",
        "    stmt = None\n",
        "    table_created = False  # track if CETAS was successful\n",
        "\n",
        "    try:\n",
        "        # Step 1: Connect and drop table if it exists\n",
        "        conn = get_jdbc_connection(config)\n",
        "        stmt = conn.createStatement()\n",
        "\n",
        "        if table_exists(stmt, config[\"external_table\"]):\n",
        "            drop_external_table(stmt, config[\"external_table\"])\n",
        "        else:\n",
        "            print(f\"‚ÑπÔ∏è Table `{config['external_table']}` does not exist. Skipping DROP.\")\n",
        "\n",
        "        # Step 2: Remove previous output files from ADLS\n",
        "        delete_adls_path(config[\"materialized_table_output_path\"])\n",
        "\n",
        "        # Step 3: Recreate external table using CETAS\n",
        "        create_external_table(stmt, config)\n",
        "        table_created = True  # only set this if no exception was raised\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error during external table refresh: {e}\")\n",
        "        raise\n",
        "\n",
        "    finally:\n",
        "        if stmt:\n",
        "            stmt.close()\n",
        "        if conn:\n",
        "            conn.close()\n",
        "        print(\"‚úÖ External table refresh step completed.\\n\")\n",
        "\n",
        "    # Step 4: Create statistics only if CETAS succeeded\n",
        "    if table_created:\n",
        "        create_statistics_for_external_table(config)\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Skipping statistics creation because the external table was not created.\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Execute\n",
        "Run the refresh function to apply all changes.\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "refresh_external_table(CONFIG)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}